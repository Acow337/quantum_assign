# Readme



### Key Installation Requirements

Before running the code, install these packages:

```
pip install qiskit qiskit-aer qiskit-machine-learning scikit-learn matplotlib numpy
```







# Picture Explanation





# Picture1: Deutsch Algorithm Results - All Cases



### **Cases 1 & 2: Constant Functions** (Top Row)

- **Measurement Results**: Both show **1024/1024 measurements = 0**
- Function Definitions:
  - **Case 1**: f(x) = 0 (always outputs 0, regardless of input)
  - **Case 2**: f(x) = 1 (always outputs 1, regardless of input)
- **Quantum Determination**: Measuring qubit q‚ÇÄ yields |0‚ü© ‚Üí **CONSTANT function detected**

### **Cases 3 & 4: Balanced Functions** (Bottom Row)

- **Measurement Results**: Both show **1024/1024 measurements = 1**
- Function Definitions:
  - **Case 3**: f(x) = x (identity: outputs 0 for input 0, outputs 1 for input 1)
  - **Case 4**: f(x) = ¬¨x (negation: outputs 1 for input 0, outputs 0 for input 1)
- **Quantum Determination**: Measuring qubit q‚ÇÄ yields |1‚ü© ‚Üí **BALANCED function detected**

## Key Theoretical Insights

### üéØ **Perfect Quantum Algorithm Performance**

- **100% Success Rate**: No statistical errors or uncertainty
- **Deterministic Results**: Every measurement gives the correct answer
- **Quantum Advantage Realized**: Single query solves what classically requires two queries

### üî¨ **Algorithm Mechanics**

#### **Quantum Circuit Flow**:

1. **Initialize**: |01‚ü© state (q‚ÇÄ=0, q‚ÇÅ=1)
2. **Superposition**: Apply H gates ‚Üí creates |+‚ü©|-‚ü© state
3. **Oracle Query**: Function evaluation in superposition
4. **Interference**: Final H gate on q‚ÇÄ creates interference pattern
5. **Measurement**: Result encodes global function property

#### **Why It Works**:

- **Quantum Parallelism**: Evaluates f(0) and f(1) simultaneously
- **Phase Kickback**: Function output affects phase of superposition
- **Interference**: Constructive/destructive interference reveals function type

### üìä **Result Interpretation**

```
Constant Functions ‚Üí Constructive interference ‚Üí Measure |0‚ü©
Balanced Functions ‚Üí Destructive interference ‚Üí Measure |1‚ü©
```

## Significance of These Results

### ‚úÖ **Theoretical Validation**

- **Oracle Abstraction Works**: Each function type produces expected quantum behavior
- **Quantum Coherence Maintained**: No decoherence or noise affecting results
- **Algorithm Universality**: Works for all possible Boolean functions of this type

### üöÄ **Computational Advantage**

- **Classical Approach**: Must query f(0) AND f(1) to determine function type
- **Quantum Approach**: Single superposition query reveals global property
- **Efficiency Gain**: 50% reduction in function evaluations (2‚Üí1)

### üéì **Educational Impact**

This demonstrates core quantum computing principles:

- **Superposition**: Computing with multiple states simultaneously
- **Interference**: Using quantum phases to extract information
- **Measurement**: Collapsing quantum information into classical bits

## Why This Matters

### üîë **Fundamental Proof of Concept**

- **First Quantum Algorithm**: Historically significant as early quantum advantage proof
- **Minimal Resources**: Only 2 qubits needed for exponential improvement
- **Clean Example**: No noise, error correction, or complex engineering required

### üåü **Broader Implications**

- **Quantum Supremacy Preview**: Shows quantum algorithms can fundamentally outperform classical ones
- **Design Principles**: Illustrates how to construct quantum algorithms using interference
- **Scalability Hints**: Suggests potential for larger quantum advantages in complex problems

## Bottom Line

These **perfect results** (1024/1024 correct measurements) demonstrate that:

1. **Quantum algorithms work as designed** when properly implemented
2. **Quantum advantage is real** for appropriately chosen problems
3. **Interference-based computation** can extract global properties efficiently
4. **Current quantum simulators** can faithfully reproduce theoretical predictions

This graph represents a **textbook example** of quantum computing success - where theory, implementation, and results align perfectly to demonstrate genuine quantum computational advantage!



# Picture2~10: Decision Boundary Visualization Plots



Excellent! These visualization results from your quantum computing assignment show the decision boundaries generated by different classical SVM kernels on three digit classification tasks. Let me explain what we're seeing:

## Overall Analysis

The plots show how different SVM kernels create decision boundaries in the 2D PCA-reduced feature space for handwritten digit classification. The data points are colored by class (blue vs red), and the background regions show the classifier's predictions.

## Key Observations by Dataset:

### Digits 3 vs 4 (Images 1-3):

- **Data characteristics**: Well-separated clusters with minimal overlap
- **PCA explained variance**: 43.8% + 10.2% = 54.0% total
- **Linear SVM**: Creates a clean straight decision boundary - works well for this linearly separable data
- **RBF SVM**: Creates a curved, more flexible boundary that follows the data distribution closely
- **Polynomial SVM**: Similar to linear but with slight curvature

### Digits 1 vs 2 (Images 4-6):

- **Data characteristics**: More overlapping clusters, harder to separate
- **PCA explained variance**: 29.5% + 18.0% = 47.5% total (lower than 3vs4)
- **Linear SVM**: Diagonal boundary struggles with the overlapping regions
- **RBF SVM**: Creates a more complex curved boundary to better handle overlaps
- **Polynomial SVM**: Similar linear-like boundary with some curvature

### Digits 0 vs 9 (Images 7-9):

- **Data characteristics**: Very well-separated clusters, almost no overlap
- **PCA explained variance**: 29.4% + 13.9% = 43.3% total
- **All kernels**: Perform similarly well due to clear separation
- **Linear SVM**: Vertical boundary works perfectly
- **RBF SVM**: Creates a smooth curved boundary
- **Polynomial SVM**: Nearly vertical boundary with slight curve

## Technical Insights:

1. **PCA Impact**: Lower explained variance ratios (like in 1vs2) indicate more complex data that's harder to represent in 2D, leading to overlapping clusters.
2. **Kernel Performance**:
   - **Linear**: Best for linearly separable data (3vs4, 0vs9)
   - **RBF**: Most flexible, handles overlapping data well (1vs2)
   - **Polynomial**: Middle ground between linear and RBF
3. **Decision Boundary Shapes**:
   - Linear boundaries are computationally efficient but limited
   - RBF creates smooth, curved boundaries that can wrap around data clusters
   - Polynomial provides moderate flexibility

## Classification Difficulty Ranking:

1. **Easiest**: 0 vs 9 (very distinct shapes)
2. **Medium**: 3 vs 4 (some similarity but generally separable)
3. **Hardest**: 1 vs 2 (both are thin vertical digits with overlap)

This visualization perfectly demonstrates why your code concluded that classical SVMs perform well - they can adapt their decision boundaries to the data complexity using different kernels, while current QSVMs lack this mature optimization and flexibility.



# Picture11: Performance Comparison Charts 



This performance comparison chart reveals the **current reality of Quantum SVM vs Classical SVM** across three critical metrics. Let me break down what each chart shows:



## 1. Accuracy Comparison (Left Chart)

### **Classical SVM Performance (Blue/Orange bars)**

- **Accuracy Range**: 0.88-1.00 (88-100%)
- **Consistent Excellence**: Most classical methods achieve near-perfect accuracy
- **Kernel Variations**: Different kernels (linear, RBF, polynomial) all perform very well
- **Dataset Robustness**: High accuracy across different digit pairs (0_vs_9, 1_vs_2, 3_vs_4)

### **Quantum SVM Performance (Green bars)**

- **Accuracy Range**: 0.96-1.00 (96-100%)
- **Surprisingly Good**: Actually performs competitively with classical methods
- **Interesting Observation**: In some cases, QSVM matches or slightly exceeds classical performance

## 2. Training Time Comparison (Middle Chart)

### **Dramatic Time Differences (Logarithmic Scale!)**

- **Classical SVM**: ~0.5-2.5 milliseconds (10‚Åª¬≥ seconds)
- **Quantum SVM**: ~1.5-3.2 milliseconds (slightly higher but comparable)
- **Key Finding**: Training times are actually quite similar, contrary to expectations

## 3. Prediction Time Comparison (Right Chart)

### **The Real Performance Gap**

- **Classical SVM**: ~0.0002-0.0003 seconds (very fast)
- **Quantum SVM**: ~0.0004-0.0006 seconds (about 2x slower)
- **Pattern**: QSVM consistently takes longer for predictions across all datasets

## Key Insights & Interpretations

### üéØ **Surprising Results**

Unlike typical QSVM vs CSVM comparisons, this shows:

- **Competitive Accuracy**: QSVM doesn't significantly underperform
- **Reasonable Training Times**: Much better than expected
- **Moderate Prediction Overhead**: Only ~2x slower, not orders of magnitude

### üîç **Why These Results Differ from Expectations**

1. **Small Dataset Effect**: With only 2D data after PCA reduction, quantum overhead is minimized
2. **Simulation Environment**: Running on classical computers, not real quantum hardware
3. **Optimized Implementation**: Modern Qiskit implementations are well-optimized
4. **Binary Classification**: Simple two-class problems don't fully stress the algorithms

### üìä **Dataset-Specific Observations**

- **0_vs_9**: Easiest classification (very different digit shapes) ‚Üí All methods excel
- **1_vs_2**: More challenging ‚Üí Slight performance variations visible
- **3_vs_4**: Moderate difficulty ‚Üí Consistent performance patterns

### ‚ö†Ô∏è **Important Caveats**

1. **Simulation vs Reality**: These are simulated quantum results, not real quantum hardware
2. **Scale Limitations**: Small 2D datasets don't represent real-world complexity
3. **Hardware Noise**: Real quantum computers would show degraded performance
4. **Optimization Maturity**: Classical SVMs benefit from decades of optimization

## Practical Implications

### ‚úÖ **Positive Takeaways**

- Quantum algorithms can achieve competitive accuracy
- Training overhead isn't prohibitively expensive for small problems
- Modern quantum simulators are quite efficient

### ‚ö†Ô∏è **Realistic Limitations**

- Prediction speed penalty still exists
- Scalability to larger datasets remains questionable
- Real quantum hardware would likely show worse performance

### üîÆ **Future Potential**

These results suggest that as quantum hardware improves and datasets grow larger, quantum SVMs might become more competitive, especially if quantum advantages emerge at scale.

## Bottom Line

This comparison shows **quantum machine learning in its best light** - competitive performance on well-suited problems in a simulation environment. However, it also reveals that even under ideal conditions, classical methods maintain practical advantages in speed and efficiency.

The results demonstrate both the **promise and current limitations** of quantum machine learning: theoretically competitive, but practically constrained by implementation overhead.
